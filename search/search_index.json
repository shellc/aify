{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Build your AI-native application in seconds. \ud83d\udee0\ufe0f AI-native application framework and runtime. Simply write a YAML file. \ud83e\udd16 Ready-to-use AI chatbot UI. Screenshots","title":"Home"},{"location":"#home","text":"Build your AI-native application in seconds. \ud83d\udee0\ufe0f AI-native application framework and runtime. Simply write a YAML file. \ud83e\udd16 Ready-to-use AI chatbot UI.","title":"Home"},{"location":"#screenshots","text":"","title":"Screenshots"},{"location":"app_template/","text":"App template Coming soon...","title":"App template"},{"location":"app_template/#app-template","text":"Coming soon...","title":"App template"},{"location":"dive_into_apps/","text":"Dive into apps User apps are stored in a directory. The files that comprise the application program include YAML files, Python code, environment variables, authentication tokens, and other static resources(such as word embeddings). The directory also contains data generated during the program's execution Directory structure your_apps_dir/ .evn .tokens your_app_1.yaml your_app_2.yaml memories/ embeddings/ static/ helpers.py .env The file contains environment variable settings, such as OPENAI_API_KEY. .token The file contains authentication information for users and permissions, used for API authentication. your_app_*.yaml The file defines the application, and a folder can contain multiple applications. memories The folder is automatically generated during program execution and is used to store data generated by the program. embeddings The folder is used to store text embedding data, and the application performs similarity searches during runtime. static The folder stores static resources required by the application. helpers.py is a collection of custom Python functions that can be invoked in the application. You can define multiple pypthon files and functions of any complexity. Set environment variables Example: OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY OPENAI_API_BASE=https://YOU_OPENAI_API_BASE Authorization Example: YOUR_GENEREATED_TOKEN_STR_FOR_AUTH|username|write ANATHORE_TOKEN_STR|\ud83e\uddb8\ud83c\udffb\u200d\u2640\ufe0f| The last column is for user permissions. \"write\" indicates that the user has write permission. Executing an application requires write permission, otherwise the user only has read permission. The \".tokens\" file is not necessary. If there is no \".tokens\" file in the application folder, it means that authentication is not required and all users can read and write anonymously. Memories Chatbot applications typically need to save conversation context data. We refer to this data as \"memories.\" You can also implement your own memory storage method. Aify is a highly scalable framework. Embeddings The \"embeddings\" directory contains some CSV files that store word embeddings. It is used to retrieve data based on similarity during program execution, allowing the application to dynamically utilize external data. Similarly, you can also implement your own embedding retrieval method. Helper functions Helper functions is a collection of custom Python functions that can be invoked in the application. You can define multiple pypthon files and functions of any complexity. This can be used to enable communication between applications and external systems. For example, it allows for real-time access to a search engine's interface to retrieve data.","title":"Dive into apps"},{"location":"dive_into_apps/#dive-into-apps","text":"User apps are stored in a directory. The files that comprise the application program include YAML files, Python code, environment variables, authentication tokens, and other static resources(such as word embeddings). The directory also contains data generated during the program's execution","title":"Dive into apps"},{"location":"dive_into_apps/#directory-structure","text":"your_apps_dir/ .evn .tokens your_app_1.yaml your_app_2.yaml memories/ embeddings/ static/ helpers.py .env The file contains environment variable settings, such as OPENAI_API_KEY. .token The file contains authentication information for users and permissions, used for API authentication. your_app_*.yaml The file defines the application, and a folder can contain multiple applications. memories The folder is automatically generated during program execution and is used to store data generated by the program. embeddings The folder is used to store text embedding data, and the application performs similarity searches during runtime. static The folder stores static resources required by the application. helpers.py is a collection of custom Python functions that can be invoked in the application. You can define multiple pypthon files and functions of any complexity.","title":"Directory structure"},{"location":"dive_into_apps/#set-environment-variables","text":"Example: OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY OPENAI_API_BASE=https://YOU_OPENAI_API_BASE","title":"Set environment variables"},{"location":"dive_into_apps/#authorization","text":"Example: YOUR_GENEREATED_TOKEN_STR_FOR_AUTH|username|write ANATHORE_TOKEN_STR|\ud83e\uddb8\ud83c\udffb\u200d\u2640\ufe0f| The last column is for user permissions. \"write\" indicates that the user has write permission. Executing an application requires write permission, otherwise the user only has read permission. The \".tokens\" file is not necessary. If there is no \".tokens\" file in the application folder, it means that authentication is not required and all users can read and write anonymously.","title":"Authorization"},{"location":"dive_into_apps/#memories","text":"Chatbot applications typically need to save conversation context data. We refer to this data as \"memories.\" You can also implement your own memory storage method. Aify is a highly scalable framework.","title":"Memories"},{"location":"dive_into_apps/#embeddings","text":"The \"embeddings\" directory contains some CSV files that store word embeddings. It is used to retrieve data based on similarity during program execution, allowing the application to dynamically utilize external data. Similarly, you can also implement your own embedding retrieval method.","title":"Embeddings"},{"location":"dive_into_apps/#helper-functions","text":"Helper functions is a collection of custom Python functions that can be invoked in the application. You can define multiple pypthon files and functions of any complexity. This can be used to enable communication between applications and external systems. For example, it allows for real-time access to a search engine's interface to retrieve data.","title":"Helper functions"},{"location":"enhance_with_python/","text":"Enhance with Python Coming soon..","title":"Enhance with Python"},{"location":"enhance_with_python/#enhance-with-python","text":"Coming soon..","title":"Enhance with Python"},{"location":"getting_started/","text":"Getting started Welcome to Aify, the AI-native application framework and runtime that allows you to ship your AI applications in seconds! With Aify, you can easily build and deploy AI-powered applications using a simple YAML file. In this guide, we will walk you through the steps to get started with Aify and create your first AI application. Installation To begin, make sure you have the following prerequisites installed on your system: Python 3.8 or higher Pip package manager Once you have the prerequisites, you can install Aify by running the following command in your terminal: pip install aify Create your first app You need to prepare a directory for your applications: mkdir ./apps Now you can start the aify service and then access http://localhost:2000 using a browser, and aify will greet you. aify run ./apps Now it's just a blank application, you can't use it for anything. Next, we will create a chatbot. Creating a YAML file aify uses a YAML file to define your AI application. This file contains all the necessary configurations and settings for your application. Here's an example of a basic YAML file: title: Chatbot model: vendor: openai name: gpt-3.5-turbo params: api_key: <YOUR_OPENAI_API_KEY> prompt: | {{#system~}} You are a helpful and terse assistant. {{~/system}} {{#each (memory.read program_name session_id n=3)}} {{~#if this.role == 'user'}} {{#user~}} {{this.content}} {{~/user}} {{/if~}} {{~#if this.role == 'assistant'}} {{#assistant~}} {{this.content}} {{~/assistant}} {{/if~}} {{~/each}} {{#user~}} {{prompt}} {{memory.save program_name session_id 'user' prompt}} {{~/user}} {{#assistant~}} {{gen 'answer' temperature=0 max_tokens=2000}} {{memory.save program_name session_id 'assistant' answer}} {{~/assistant}} variables: - name: prompt type: input - name: answer type: output Here are some simple explanations about this YAML file: The title represents the name of this application. The model section defines the AI model used by this application and the runtime parameters required by the model. The prompt section is used to drive the application's execution. Aify uses the guidance software package provided by Microsoft to drive the execution of the AI program. Guidance provides a way to operate as a Chain of Thought. Since guidance uses the Handlebars template system, the format of this section is actually a Handlebars template.The prompt section contains some helper functions that allow the AI model to dynamically change its runtime behavior, helping us achieve more complex functionality. These functions are built-in to aify, but you can also write your own helper functions in Python to accomplish specific tasks. The terms \"system,\" \"user,\" and \"assistant\" are used to define the roles in an LLM-based chat task. \"memory.read\" and \"memory.write\" are built-in helper functions in Aify, used to save and load the conversation history of users and AI. \"each\" and \"if\" are branch control statements provided by Handlebars. \"gen\" is the function provided by \"guidance\" to indicate the execution of LLM generation tasks. The variables section defines the input and output variables of the application, which are used for external systems to access the data generated by AI through an API. Play with your AI app Now go back to your browser and refresh the page. You will see the application you just created. You can have some conversations with it, just like ChatGPT. aify is not a chatbot Although aify provides a chatbot interface, its main purpose is not to provide a replacement for ChatGPT or a competitive conversation application. The chatbot UI is only for convenient debugging of AI applications. Of course, you can indeed use it as a chatbot for daily use. The main goal of aify is to provide an efficient framework for developing and deploying AI applications. If your goal is to develop your own complex AI applications, you should pay more attention to the APIs and extension mechanisms provided by aify.","title":"Getting started"},{"location":"getting_started/#getting-started","text":"Welcome to Aify, the AI-native application framework and runtime that allows you to ship your AI applications in seconds! With Aify, you can easily build and deploy AI-powered applications using a simple YAML file. In this guide, we will walk you through the steps to get started with Aify and create your first AI application.","title":"Getting started"},{"location":"getting_started/#installation","text":"To begin, make sure you have the following prerequisites installed on your system: Python 3.8 or higher Pip package manager Once you have the prerequisites, you can install Aify by running the following command in your terminal: pip install aify","title":"Installation"},{"location":"getting_started/#create-your-first-app","text":"You need to prepare a directory for your applications: mkdir ./apps Now you can start the aify service and then access http://localhost:2000 using a browser, and aify will greet you. aify run ./apps Now it's just a blank application, you can't use it for anything. Next, we will create a chatbot. Creating a YAML file aify uses a YAML file to define your AI application. This file contains all the necessary configurations and settings for your application. Here's an example of a basic YAML file: title: Chatbot model: vendor: openai name: gpt-3.5-turbo params: api_key: <YOUR_OPENAI_API_KEY> prompt: | {{#system~}} You are a helpful and terse assistant. {{~/system}} {{#each (memory.read program_name session_id n=3)}} {{~#if this.role == 'user'}} {{#user~}} {{this.content}} {{~/user}} {{/if~}} {{~#if this.role == 'assistant'}} {{#assistant~}} {{this.content}} {{~/assistant}} {{/if~}} {{~/each}} {{#user~}} {{prompt}} {{memory.save program_name session_id 'user' prompt}} {{~/user}} {{#assistant~}} {{gen 'answer' temperature=0 max_tokens=2000}} {{memory.save program_name session_id 'assistant' answer}} {{~/assistant}} variables: - name: prompt type: input - name: answer type: output Here are some simple explanations about this YAML file: The title represents the name of this application. The model section defines the AI model used by this application and the runtime parameters required by the model. The prompt section is used to drive the application's execution. Aify uses the guidance software package provided by Microsoft to drive the execution of the AI program. Guidance provides a way to operate as a Chain of Thought. Since guidance uses the Handlebars template system, the format of this section is actually a Handlebars template.The prompt section contains some helper functions that allow the AI model to dynamically change its runtime behavior, helping us achieve more complex functionality. These functions are built-in to aify, but you can also write your own helper functions in Python to accomplish specific tasks. The terms \"system,\" \"user,\" and \"assistant\" are used to define the roles in an LLM-based chat task. \"memory.read\" and \"memory.write\" are built-in helper functions in Aify, used to save and load the conversation history of users and AI. \"each\" and \"if\" are branch control statements provided by Handlebars. \"gen\" is the function provided by \"guidance\" to indicate the execution of LLM generation tasks. The variables section defines the input and output variables of the application, which are used for external systems to access the data generated by AI through an API.","title":"Create your first app"},{"location":"getting_started/#play-with-your-ai-app","text":"Now go back to your browser and refresh the page. You will see the application you just created. You can have some conversations with it, just like ChatGPT.","title":"Play with your AI app"},{"location":"getting_started/#aify-is-not-a-chatbot","text":"Although aify provides a chatbot interface, its main purpose is not to provide a replacement for ChatGPT or a competitive conversation application. The chatbot UI is only for convenient debugging of AI applications. Of course, you can indeed use it as a chatbot for daily use. The main goal of aify is to provide an efficient framework for developing and deploying AI applications. If your goal is to develop your own complex AI applications, you should pay more attention to the APIs and extension mechanisms provided by aify.","title":"aify is not a chatbot"},{"location":"rest_api/","text":"RESTful API Coming soon...","title":"RESTful API"},{"location":"rest_api/#restful-api","text":"Coming soon...","title":"RESTful API"},{"location":"deploy_to_clouds/google_appengine/","text":"Deploy to google app engine You need to install and configure your Google Cloud CLI before deploying your apps to Google Cloud Engine. https://cloud.google.com/sdk/docs/install Examples: https://github.com/shellc/aify/tree/main/examples cd examples cp deploy-to-google-appengine/requirements.txt . gcloud app deploy --appyaml ./deploy-to-google-appengine/app.yaml Make sure that the memory module in your app template is specified as aify.memories.google_cloud_datastore . You can also set it as an environment variable in the .env file. .env: AIFY_MEMORY_STORAGE=aify.memories.google_cloud_datastore your_app_template.yaml: modules: memory: $AIFY_MEMORY_STORAGE","title":"Deploy to google app engine"},{"location":"deploy_to_clouds/google_appengine/#deploy-to-google-app-engine","text":"You need to install and configure your Google Cloud CLI before deploying your apps to Google Cloud Engine. https://cloud.google.com/sdk/docs/install Examples: https://github.com/shellc/aify/tree/main/examples cd examples cp deploy-to-google-appengine/requirements.txt . gcloud app deploy --appyaml ./deploy-to-google-appengine/app.yaml Make sure that the memory module in your app template is specified as aify.memories.google_cloud_datastore . You can also set it as an environment variable in the .env file. .env: AIFY_MEMORY_STORAGE=aify.memories.google_cloud_datastore your_app_template.yaml: modules: memory: $AIFY_MEMORY_STORAGE","title":"Deploy to google app engine"},{"location":"examples/chatbot/","text":"Chatbot Coming soon...","title":"Chatbot"},{"location":"examples/chatbot/#chatbot","text":"Coming soon...","title":"Chatbot"},{"location":"examples/llm_generation/","text":"LLM Generation Coming soon...","title":"LLM Generation"},{"location":"examples/llm_generation/#llm-generation","text":"Coming soon...","title":"LLM Generation"}]}